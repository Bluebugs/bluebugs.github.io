<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>Tests Debt | Cedric Bail</title>
<meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="Avoiding Tech debt in your tests!"><meta name=generator content="Hugo 0.136.0"><meta name=robots content="index, follow"><meta name=author content="Cedric Bail"><link rel=stylesheet href=/ananke/css/main.min.b3c9b096ae6eeeda4ad54a0732df5f88066f9973f3d966a315b2014cf76b8bc2.css><link rel=canonical href=http://bluebugs.github.io/blogs/tests-debt/><meta property="og:url" content="http://bluebugs.github.io/blogs/tests-debt/"><meta property="og:site_name" content="Cedric Bail"><meta property="og:title" content="Tests Debt"><meta property="og:description" content="Avoiding Tech debt in your tests!"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2024-11-09T14:20:32-07:00"><meta property="article:modified_time" content="2024-11-09T14:20:32-07:00"><meta itemprop=name content="Tests Debt"><meta itemprop=description content="Avoiding Tech debt in your tests!"><meta itemprop=datePublished content="2024-11-09T14:20:32-07:00"><meta itemprop=dateModified content="2024-11-09T14:20:32-07:00"><meta itemprop=wordCount content="1561"><meta name=twitter:card content="summary"><meta name=twitter:title content="Tests Debt"><meta name=twitter:description content="Avoiding Tech debt in your tests!"></head><body class="ma0 avenir bg-near-white production"><header class="cover bg-center" style=background-image:url(http://bluebugs.github.io/images/kicking-horse.jpg)><div class=bg-black-60><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">Cedric Bail</a><div class="flex-l items-center"><ul class="pl0 mr3"><li class="list f5 f4-ns fw4 dib pr3"><a class="hover-white no-underline white-90" href=/blogs/ title="Blog page">Blog</a></li></ul><div class=ananke-socials></div></div></div></nav><div class="tc-l pv6 ph3 ph4-ns"><div class="f2 f1-l fw2 white-90 mb0 lh-title">Tests Debt</div><div class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">Avoiding Tech debt in your tests!</div></div></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked ttu">Blog</aside><div id=sharing class="mt3 ananke-socials"></div><h1 class="f1 athelas mt3 mb1">Tests Debt</h1><p class=tracked>By <strong>Cedric Bail</strong></p><time class="f6 mv4 dib tracked" datetime=2024-11-09T14:20:32-07:00>November 9, 2024</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links black pr4-l w-two-thirds-l"><p>Tests should help you release code faster and with confidence. Yet, for many developers, testing has the opposite effect, creating delays and frustration. Here, I&rsquo;ll explore common pitfalls in testing and suggest better practices to make tests truly beneficial.</p><p>We have all heard that we need to have more tests and that we should have as close to 100% tests coverage as possible. Despite this effort, we still encounter bugs. We still do manual testing and overall a lot of developers do not trust their tests to actually catch anything useful. Why is that?</p><h1 id=identifying-_technical-debt_-through-its-symptoms>Identifying <em>Technical Debt</em> through its symptoms</h1><p>Diagnosing technical debt often starts by observing its symptoms, such as missed deadlines or delays in delivering new features. Increase in bugs and instability faced by the users of the software is also another symptom. The more <em>technical debt</em> there is in your code, the harder it is to predict the outcome of a planned code change. This impacts both the quality of the result and when that result is available.</p><p>The easy answer from management when they see this kind of problem is to push the silver bullet aka more tests and code coverage! Of course this won&rsquo;t pay down any of the existing <em>technical debt</em>, but at least next release quality should be good&mldr; right?</p><h1 id=bugs-and-unpredictable-releases>Bugs and unpredictable releases</h1><p>And still, this doesn&rsquo;t solve the problem! In fact, it likely make things worth. Every line of code that is written will have to live for a decade if it is part of any successful software. This means every line of code that is added to a project has the potential to add <em>technical debt</em>. This includes TESTS too!</p><p>We were told that tests would bring us peace and enable us to confidently release software. How is that not working? Consider what your tests are actually validating for the specific code you&rsquo;re working with. Most of us, software developers, are actually not writing any complex algorithm, but just gluing a bunch of different library, executable and online services to provide new functionality. What most of us do, is write code that integrate things together. This can&rsquo;t be tested properly with unit test.</p><p>Unit tests are useful for verifying algorithms or specific functions, like ensuring a sorting function orders items correctly. But when testing code with a lot of dependencies, unit test are not the solution. Why would a mock of your dependencies actually test anything? It duplicate the assumption you had when writing your code. This duplication of assumption is the core of your <em>technical debt</em> in your tests. When you will discover a bug, you will have to change both your code and your test. Your test are not testing anything, they are preventing you from changing your code.</p><blockquote><p>Note: At least, when you use mock, you can rely on code generation and not pay the cost of writing or maintaining those line. There will never be a good reason to write mock or stubs by hands.</p></blockquote><p>This is the textbook definition of <em>technical debt</em>. Something that make you slow at doing any change without providing any benefit.</p><h1 id=better-tests>Better tests</h1><p>Understanding how technical debt accumulates in tests is just the beginning. Now, let&rsquo;s explore better testing practices that can reduce this debt and enhance test reliability.</p><p>The first step is to recognize when your tests are enforcing belief instead of testing it. And the easiest step for most of us to solve this problem is to not write unit test. We are integrating things together, we should write integration tests and end to end tests, not unit test. Another regular mistake is in mocking dependencies in unit tests, as it often recreates the same assumptions that went into the original code. This leads to duplicated assumptions that accumulate technical debt. For example, mocking a database may hide real-world issues, which can cause bugs to surface later in production. So stop writing unit test!</p><p>We have amazing tools today to write this. First a bit of difference between integration tests and end to end tests.</p><ul><li><strong>Integration tests</strong>: Run before deployment and ensure each module works with its dependencies.</li><li><strong>End to end tests</strong>: Verify that your code functions as expected in the production environment.</li></ul><p>For integration testing, we have a lot of tools that help. You can now spin all your dependencies using <a href=https://testcontainers.com/>testcontainer</a> with <a href=https://www.docker.com/>docker</a>. For example, you could use testcontainer to set up a temporary PostgreSQL database with Docker, allowing tests to interact with a real database instead of mocks. This ensures your tests behave more like they would in production. Even your laptop is fast enough to spin up a database server, a cache service and let a few tests run against it. If you believe this is going to slow you down, switch to use something like SQLite for your local testing and <a href=https://turso.tech/>Turso</a> for your database.</p><p>Still sometimes, you need to use some SaaS service. Prefer the one that have an open source implementation that allow you to actually do your integration tests without a mock. For example, even if you use <a href=https://tailscale.com/>Tailscale</a> for your connection between services, you can use <a href=https://github.com/juanfont/headscale>Headscale</a> in combination with testcontainer for your integration tests.</p><p>Some of you might need to connect to some appliance and again that might have been something the first answer was, let&rsquo;s use mock to emulate this device. Still this might not be necessary the best answer. Consider that for <a href=https://mikrotik.com/>Mikrotik Router</a>, you can actually run their OS in a <a href=https://github.com/EvilFreelancer/docker-routeros>container</a> and tests your service against it! If it is possible for router, whatever your appliance, you should really get it running in the &ldquo;cloud&rdquo; if just for better testing!</p><h1 id=step-up-your-tests>Step up your tests</h1><p>While integration tests improve test coverage, they might not fully simulate the production environment. End-to-end testing fills this gap.</p><p>Integration tests are great, but they don&rsquo;t actually tests the final service as it is running in production. And your integration tests, might miss things for that reason. A solution to this problem is to deploy your application in your production environment. Tests it there. And when all tests pass, switch the traffic to the newly deployed application. This is the basis for an end to end test.</p><p>This is easy for web application, and you should have no excuse to not already have it. With tool like <a href=https://www.cypress.io/>cypress</a> or <a href=https://playwright.dev/>playwright</a>, you can easily run tests against your application, check the result and assess if everything looks good as if a human was going through it. Actually this is a lot better than any manual testing as it will not miss any details nor forget to tests some old feature. As you move forward your tests would only grow and whatever the size of your application, your tests will scale.</p><p>It is slightly harder when doing native application and require building or using infrastructure that allows for on devices testing. Some OS are harder than other, some are easier. Windows and Linux are the easiest to work with. While iOS might be the hardest. Never the less, if you want to be able to deploy your application to this OS and you want to be confident that you are not breaking anything, invest the time to build that infrastructure. For anyone doing native application, keep in mind the explosion of possibility. Let say you support Windows, Mac, Linux, Android and iOS. That&rsquo;s 5 OS. You then support x86_64 and ARM64. That 2 architectures. Now multiply the manual testing of your application 10 times for each features.</p><h1 id=drinking-your-own-champagne>Drinking your own champagne</h1><p>If there is one space which is guaranteed to never scale with manual testing, it is native application, but even a web application will not necessarily behave the same on Chrome, Firefox and Safari. So every time you do some scenario manually, take the necessary 30min to write the equivalent integration or end to end tests. Next time you add a feature, this tests will ensure that you still have all your old features working.</p><p>Manual testing is something that developer feel good about, as they see the result of their work, but it just work on their computer and doesn&rsquo;t lead to any repeatable result. Also developers can be blind to bugs and issues they get accustomed to.</p><p>The solution to this, is <strong>to drink your own champagne</strong> (Formerly <strong>eat your own dog food</strong>, but definitively champagne is better and I am french, so let&rsquo;s go with Champagne).</p><p>Drinking your own champagne means using your application as it exists in its current form, similar to a beta program. Deploying daily to a shared environment allows developers and selected users to spot issues early and provide feedback. This iterative approach improves quality and stability with each release.</p><p>If you have good integration tests and end to end tests, this beta program should be always in a usable state. With the ability for the non developers user to report and ask improvement ahead of a release to a larger base, this is a critical improvement to have quality release.</p><h1 id=conclusion>Conclusion</h1><p>In summary, to release with confidence:</p><ul><li>Shift focus from unit to integration tests.</li><li>Implement end-to-end tests to simulate real-world use.</li><li>Regularly use the product as it’s being built.</li></ul><p>Implementing these practices requires some effort, but it will steadily reduce technical debt in your testing process, making your software more reliable and easier to maintain.</p><ul class=pa0></ul><div class="mt6 instapaper_ignoref"><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//bluebugs.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a><div id=commento></div><script defer src=https://cdn.commento.io/js/commento.js></script></div></div><aside class="w-30-l mt6-l"></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=http://bluebugs.github.io/>&copy; Cedric Bail 2025</a><div><div class=ananke-socials></div></div></div></footer></body></html>